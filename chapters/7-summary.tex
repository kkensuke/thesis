\newgeometry{top=10truemm,bottom=20truemm,left=20truemm,right=20truemm}
\chapter{結論}

% 目的
近年、機械学習はさまざまな分野で応用され、著しい発展を遂げている。一方で、計算量が膨大であり、計算資源の不足が懸念されている。そこで、量子コンピューターによって機械学習を効率化するための研究が盛んに行われている。本研究は、NISQ 上での実装が可能な変分量子アルゴリズムの文脈において、教師あり量子機械学習の効率化に関する研究を行った。

量子機械学習アルゴリズムの効率化においては、データ入力が重要であることが指摘されている一方で、バレンプラトーという勾配消失問題との関連も指摘されている。バレンプラトーには、量子回路の深さ、オブザーバブルの局所性、ノイズ、データの入力が関係していることが知られている。どれか一つの原因でも存在すると、計算量は量子ビット数に関して指数関数的に増大してしまい、学習がほとんど進まない。しかしながら、これまでのバレンプラトーについては主に学習回路の構造に着目して研究されてきたため、データ入力がバレンプラトーに与える影響は十分には理解されていなかった。そこで、本研究は、量子機械学習に特有のデータ入力がバレンプラトーに与える影響を評価した。
特に、量子機械学習おける識別モデルのバレンプラトーについて、コスト関数の勾配の分散のスケーリングを評価することを目的とした。

% 結果、新規性、考察、貢献
第\ref{chap:upper-bound}章では、量子機械学習おける識別モデルのコスト関数のバレンプラトーについて、学習回路やオブザーバブルの局所性によるバレンプラトーが起きない設定の下で、コスト関数の勾配の分散の上界をデータ入力の観点から導出し、数値的にも検証を行った。
その結果、データ入力後の状態のエンタングルメントや入力回路の表現能力が大きいほど、コスト関数の勾配の分散の上界が小さくなり、バレンプラトーにつながることが明らかになった。
また、量子回路に Depolarizing ノイズを加えた場合に、その上界が更に小さくなることを示した。

第\ref{chap:lower-bound}章では、量子機械学習における識別モデルのコスト関数のバレンプラトーについて、特に、絶対誤差のコスト関数の勾配の分散の下界を、ガウス分布に従う入力データの観点から導出した。これにより、絶対誤差のコスト関数の勾配の分散の下界において、入力データの分散が重要な役割を果たすことを示した。そして、特定の場合において、バレンプラトーを引き起こさないための訓練データの分散に関する十分条件を得た。
また、二乗誤差や交差エントロピー誤差のコスト関数の勾配の分散は、絶対誤差のコスト関数の勾配の分散と同じようにスケールすることを数値的に示した。これにより、量子機械学習におけるバレンプラトーの解析では、どれか1つのコスト関数の勾配の分散を評価すれば十分であると推測される。

% 展望
今後必要となる研究には、次の2点が挙げられる。
まず、本研究では学習回路に単純な構造を仮定したが、より複雑な構造を用いた場合のスケーリングを調べることが望まれる。
また、本研究では量子回路学習モデルのバレンプラトーについてのみ議論したが、より一般的な議論のためには、Data reuploading モデルについても解析が必要である。

しかし、訓練可能性だけが、量子機械学習の性能を決定するわけではない。データ入力のための量子回路の構造には、古典コンピューターによる効率的な計算が難しいこと、汎化性能が高いことなども重要である。将来的に、これらの性能についても評価した上で、量子機械学習のデータ入力を設計することが期待される。
\restoregeometry